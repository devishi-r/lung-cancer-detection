{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0fc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: Study Description\n",
      "Unique Values (52): ['ThoraxAThoraxRoutine Adult' 'Chest' 'C-SP Chest' 'lungc' 'POS' 'LUNG'\n",
      " 'lungccc' 'CHEST' 'LUNGC' 'C-J' 'lung' 'LUNGCTA' 'chc'\n",
      " 'HeadBHeadSeq6MM Adult' 'CHC' 'CC' 'ch' '5mm chest' 'HeadBHead6MM Adult'\n",
      " 'ABC' 'cc' 'lung3D' 'lungc GSI' 'Chest 3' 'e1 lung'\n",
      " 'Thorax01ThoraxRoutine Adult' 'Chest  3D IMR' 'Chest  3D' 'CH CH.3D'\n",
      " 'Chest 3D' 'chest.3d' 'chest' 'ch.3d ao.cta' 'C.3D' 'ch.3d' 'CHESTC'\n",
      " 'PET01PTheadlung Adult' 'PET02WholebodyOnly Adult'\n",
      " 'PET03WholebodyFirstHead Adult' 'PET03CBMWholebodyFirstHead Adult'\n",
      " 'PETNEW03CBMWholebodyFirstHead Adult' 'PET01WholebodyFirstBody Adult'\n",
      " 'PETNEW02CBMWholebodyOnly Adult' 'PET07PTheadlung Adult'\n",
      " 'PET08WholebodyOnly Adult' 'PET02CBMWholebodyOnly Adult'\n",
      " 'PET02CBMLungOnly Adult' 'CH' 'e1' 'ThoraxThoraxabdo Adult' 'lungC'\n",
      " 'Chest CT']\n",
      "\n",
      "Column: Series Description\n",
      "Unique Values (68): ['ThoraxRoutine  8.0.0  B40f' '5mm' 'ThoraxRoutine  10.0  B40f'\n",
      " 'ThoraxRoutine  8.0.0  B70f' 'ThoraxRoutine  10.0  B70f' '5mm Lung SS50'\n",
      " 'A phase 5mm Stnd SS50' 'Recon 2 5mm' 'Smart Prep Series' '5mm Stnd SS50'\n",
      " 'd phase lung' '1.25mm' 'tmp  ThoraxRoutine  RTD'\n",
      " 'ThoraxRoutine  2.0.0  B40f' 'ThoraxRoutine  5.0.0  B70f' 'Recon 2'\n",
      " '5mm Std' '0.625mm' 'Scout' 'Recon 3 A phase 5mm Stnd SS50'\n",
      " 'AbdRoutine  3.0  B40f' 'Recon 3 A phase 5mm QC' 'A phase 5mm QC'\n",
      " '5mm Lung' '10mm' 'Thorax  5.0  B31f' 'Thorax  5.0  B80f'\n",
      " 'Thorax  1.0  B31f' 'Thorax  6.0  B80f' 'Thorax  6.0  B31f'\n",
      " 'Thorax  1.0  B70f' 'Recon 3 5mm' 'iDose 2' 'iDose 4'\n",
      " 'lung IDose iDose 4' 'lung iDose 3' 'IMR' 'FBP' 'Hip  3.0  B31s'\n",
      " 'Hip  3.0  B70s' 'AbdRoutine  5.0  B40f' 'iDose 3' 'Chest 5mm LUNG'\n",
      " 'Chest 5mm STND' '1.25mm C' '5mm C' 'Chest 0.25 MM' 'stnd 0.25 MM'\n",
      " 'A phase 5mm' 'ThoraxRoutine  6.0.0  B70f' 'ThoraxRoutine  7.0.0  B40f'\n",
      " 'Range-CT WB  1.0  B30f-Tra-ALPHA Range' 'ALPHA Range' 'CT WB  3.0  B30f'\n",
      " 'PET WB Corrected' 'ALPHA Range1' 'CT WB  1.0  B30f' 'CT lung  3.0  B70f'\n",
      " 'Thorax  3.0  B70f' 'ALPHA Range2'\n",
      " 'Range-CT WB  3.0  B30f-Tra-ALPHA Range'\n",
      " 'Range-Thorax  1.0  B70f-Tra-ALPHA Range' 'Thorax  5.0  B70f' 'A iDose 2'\n",
      " 'V iDose 2' 'D iDose 2' 'lung' 'Range-CT WB  1.0  B30f-Tra-MPR Range']\n",
      "\n",
      "Column: Manufacturer\n",
      "Unique Values (3): ['SIEMENS' 'Philips' 'GE MEDICAL SYSTEMS']\n",
      "\n",
      "Column: Modality\n",
      "Unique Values (2): ['CT' 'PT']\n",
      "\n",
      "Column: SOP Class Name\n",
      "Unique Values (3): ['CT Image Storage' 'Secondary Capture Image Storage'\n",
      " 'Positron Emission Tomography Image Storage']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('metadata.csv')\n",
    "selected_columns = ['Study Description', 'Series Description', 'Manufacturer', 'Modality', 'SOP Class Name']\n",
    "for col in selected_columns:\n",
    "    unique_vals = df[col].unique()\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Unique Values ({len(unique_vals)}): {unique_vals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a5c932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files (across all subfolders) per category:\n",
      "Category A: 184305 files\n",
      "Category B: 17106 files\n",
      "Category E: 808 files\n",
      "Category G: 48916 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "parent_dir = \"Lung-PET-CT-Dx/\"\n",
    "\n",
    "categories = ['A', 'B', 'E', 'G']\n",
    "category_file_counts = defaultdict(int)\n",
    "\n",
    "pattern = re.compile(r\"Lung_Dx-([ABEG])\\d+\", re.IGNORECASE)\n",
    "\n",
    "for item in os.listdir(parent_dir):\n",
    "    user_folder_path = os.path.join(parent_dir, item)\n",
    "    \n",
    "    # Ensure it's a directory and matches our naming pattern\n",
    "    if os.path.isdir(user_folder_path):\n",
    "        match = pattern.match(item)\n",
    "        if match:\n",
    "            category = match.group(1).upper()\n",
    "            if category in categories:\n",
    "                for root, dirs, files in os.walk(user_folder_path):\n",
    "                    category_file_counts[category] += len(files)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of image files (across all subfolders) per category:\")\n",
    "for category in categories:\n",
    "    print(f\"Category {category}: {category_file_counts[category]} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb89595",
   "metadata": {},
   "source": [
    "conditional GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ff82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import torchvision.transforms as T\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torchvision.utils import make_grid, save_image\n",
    "# import os\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a09eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # config\n",
    "# IMAGE_SIZE = 128\n",
    "# LATENT_DIM = 100\n",
    "# NUM_CLASSES = 4  # e.g., A, B, E, G\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 100\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a886006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specify dataset\n",
    "# import os\n",
    "# import pydicom  # For reading DICOM files\n",
    "# import numpy as np  # For numerical operations, especially handling image data\n",
    "# from torch.utils.data import Dataset, DataLoader  # PyTorch Dataset and DataLoader\n",
    "# from torchvision import transforms  # For image transformations\n",
    "# import torch #Pytorch\n",
    "# from PIL import Image #For image operations\n",
    "\n",
    "# class LungCancerDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     A PyTorch Dataset class for loading lung cancer DICOM data from a nested directory structure.\n",
    "#     The structure is assumed to be: root_dir/user/study_description/series_description/dicom_files.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "#         \"\"\"\n",
    "#         Initializes the dataset.\n",
    "\n",
    "#         Args:\n",
    "#             root_dir (str): The root directory of the dataset.\n",
    "#             transform (callable, optional): A function/transform to apply to the images. Defaults to None.\n",
    "#             target_transform (callable, optional): A function/transform to apply to the targets. Defaults to None.\n",
    "#         \"\"\"\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#         self.file_paths = self._load_file_paths()  # Get all DICOM file paths\n",
    "#         self.labels = self._load_labels()\n",
    "\n",
    "#     def _load_file_paths(self):\n",
    "#         \"\"\"\n",
    "#         Walks through the directory structure and gathers all DICOM file paths.\n",
    "\n",
    "#         Returns:\n",
    "#             list: A list of strings, where each string is the full path to a DICOM file.\n",
    "#         \"\"\"\n",
    "#         file_paths = []\n",
    "#         for user_dir in os.listdir(self.root_dir):\n",
    "#             user_path = os.path.join(self.root_dir, user_dir)\n",
    "#             if os.path.isdir(user_path):  # Ensure it's a directory\n",
    "#                 for study_dir in os.listdir(user_path):\n",
    "#                     study_path = os.path.join(user_path, study_dir)\n",
    "#                     if os.path.isdir(study_path):\n",
    "#                         for series_dir in os.listdir(study_path):\n",
    "#                             series_path = os.path.join(study_path, series_dir)\n",
    "#                             if os.path.isdir(series_path):\n",
    "#                                 for file_name in os.listdir(series_path):\n",
    "#                                     if file_name.endswith(\".dcm\"):  # Only include DICOM files\n",
    "#                                         file_path = os.path.join(series_path, file_name)\n",
    "#                                         file_paths.append(file_path)\n",
    "#         return file_paths\n",
    "\n",
    "#     def _load_labels(self):\n",
    "#         \"\"\"\n",
    "#         Loads labels.  This function now returns a list of None values,\n",
    "#         assuming you do not have labels.\n",
    "\n",
    "#         Returns:\n",
    "#            list: A list of None values, one for each file path.\n",
    "#         \"\"\"\n",
    "#         return [None] * len(self.file_paths)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         \"\"\"\n",
    "#         Returns the total number of items in the dataset.\n",
    "\n",
    "#         Returns:\n",
    "#             int: The number of DICOM files.\n",
    "#         \"\"\"\n",
    "#         return len(self.file_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"\n",
    "#         Reads a DICOM file, processes it, and returns the image and its label (which is None in this case).\n",
    "\n",
    "#         Args:\n",
    "#             idx (int): Index of the file to load.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: (image, label), where image is a PyTorch tensor and label is None.\n",
    "#         \"\"\"\n",
    "#         file_path = self.file_paths[idx]\n",
    "#         try:\n",
    "#             dicom_file = pydicom.dcmread(file_path)  # Read the DICOM file\n",
    "#             image = dicom_file.pixel_array  # Get the pixel data\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error reading DICOM file: {file_path}. Skipping. Error: {e}\")\n",
    "#             # Skip the faulty file.  This is the crucial change.\n",
    "#             return torch.zeros((1, 256, 256)), None\n",
    "\n",
    "#         # Check the image shape and handle accordingly\n",
    "#         if len(image.shape) == 2:\n",
    "#             # Grayscale: (H, W) -> (1, H, W)\n",
    "#             image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "#         elif len(image.shape) == 3:\n",
    "#             if image.shape[2] == 3:\n",
    "#                 # RGB: (H, W, 3) -> (3, H, W) and convert to grayscale\n",
    "#                 image = Image.fromarray(image)\n",
    "#                 image = image.convert('L')\n",
    "#                 image = np.array(image)\n",
    "#                 image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "#             else:\n",
    "#                 # Assume it's already in (C, H, W) format if the channel is not 3\n",
    "#                 image = image\n",
    "#         else:\n",
    "#             raise ValueError(f\"Image shape {image.shape} not supported. Expected (H, W) or (C, H, W)\")\n",
    "\n",
    "#         image = (image - np.min(image)) / (np.max(image) - np.min(image))  # Normalize to [0, 1]\n",
    "#         image = torch.from_numpy(image).float()  # Convert to float tensor\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)  # Apply transformations\n",
    "\n",
    "#         label = self.labels[idx]  # Get the label (which is None in this version)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "\n",
    "#         return image, label\n",
    "\n",
    "#     def get_labels(self):\n",
    "#         \"\"\"\n",
    "#         Returns the labels.\n",
    "\n",
    "#         Returns:\n",
    "#             list: A list of labels.\n",
    "#         \"\"\"\n",
    "#         return self.labels\n",
    "\n",
    "\n",
    "# def create_dataloader(root_dir, batch_size=32, shuffle=True, transform=None, target_transform=None, num_workers=0):\n",
    "#     \"\"\"\n",
    "#     Creates a PyTorch DataLoader for the lung cancer DICOM dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root_dir (str): The root directory of the dataset.\n",
    "#         batch_size (int, optional): The batch size. Defaults to 32.\n",
    "#         shuffle (bool, optional): Whether to shuffle the data. Defaults to True.\n",
    "#         transform (callable, optional): A function/transform to apply to the images. Defaults to None.\n",
    "#         target_transform (callable, optional): A function/transform to apply to the targets. Defaults to None.\n",
    "#         num_workers (int, optional): Number of workers for the DataLoader. Defaults to 0.\n",
    "\n",
    "#     Returns:\n",
    "#         torch.utils.data.DataLoader: A PyTorch DataLoader.\n",
    "#     \"\"\"\n",
    "#     dataset = LungCancerDataset(root_dir, transform, target_transform)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "#     return dataloader, dataset.get_labels()  # Return the dataloader and the labels\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Example usage:\n",
    "#     root_directory = 'Lung-PET-CT-Dx/'  # Replace with your actual root directory\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((256, 256)),  # Example transformation: resize images\n",
    "#         #transforms.ToTensor(),  # Convert to tensor (already done in dataset, so removed from here)\n",
    "#     ])\n",
    "\n",
    "#     dataloader, labels = create_dataloader(root_directory, batch_size=32, shuffle=True, transform=transform)\n",
    "\n",
    "#     # Iterate over the dataloader to get batches of images and labels.\n",
    "#     for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "#         print(f\"Batch {batch_idx}:\")\n",
    "#         print(\"Image batch shape:\", images.shape)  # Should be [batch_size, 1, 256, 256]\n",
    "#         print(\"Labels:\", labels)  # Should be a list of None values\n",
    "#         #print(images) # prints the image tensors\n",
    "#         if batch_idx == 1:  # Only process a couple of batches for demonstration\n",
    "#             break\n",
    "#     print(f\"Number of items in the dataset: {len(dataloader.dataset)}\")\n",
    "#     print(f\"Number of batches: {len(dataloader)}\")\n",
    "#     print(f\"Labels: {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5669d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom as dicomio\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def loadlist(path):\n",
    "    list = os.listdir(path)\n",
    "    list.sort()\n",
    "    return list\n",
    "\n",
    "\n",
    "def loadFile(filename):\n",
    "    ds = sitk.ReadImage(filename)\n",
    "    img_array = sitk.GetArrayFromImage(ds)\n",
    "    if len(img_array.shape) == 3:\n",
    "        frame_num, width, height = img_array.shape\n",
    "        ch = 1\n",
    "        return img_array, frame_num, width, height, ch\n",
    "    elif len(img_array.shape) == 4:\n",
    "        frame_num, width, height, ch = img_array.shape\n",
    "        return img_array, frame_num, width, height, ch\n",
    "\n",
    "\n",
    "def loadFileInformation(filename):\n",
    "    information = {}\n",
    "    ds = dicomio.read_file(filename, force=True)\n",
    "    information['dicom_num'] = ds.SOPInstanceUID\n",
    "    # information['PatientID'] = ds.PatientID\n",
    "    # information['PatientName'] = ds.PatientName\n",
    "    # information['PatientBirthDate'] = ds.PatientBirthDate\n",
    "    # information['PatientSex'] = ds.PatientSex\n",
    "    # information['StudyID'] = ds.StudyID\n",
    "    # information['StudyDate'] = ds.StudyDate\n",
    "    # information['StudyTime'] = ds.StudyTime\n",
    "    # information['InstitutionName'] = ds.InstitutionName\n",
    "    # information['Manufacturer'] = ds.Manufacturer\n",
    "    # information['NumberOfFrames'] = ds.NumberOfFrames\n",
    "    return information\n",
    "\n",
    "\n",
    "def showImage(img_array):\n",
    "    img_array = img_array\n",
    "    img_bitmap = Image.fromarray(img_array)\n",
    "    # img_bitmap.show()\n",
    "    return img_bitmap\n",
    "\n",
    "\n",
    "def MatrixToImage(data, ch):\n",
    "    # data = (data+1024)*0.125\n",
    "    # new_im = Image.fromarray(data.astype(np.uint8))\n",
    "    # new_im.show()\n",
    "    if ch == 3:\n",
    "        img_rgb = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "    if ch == 1:\n",
    "        data = (data + 1024) * 0.125\n",
    "        img_rgb = data.astype(np.uint8)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def PETToImage(img_array, color_reversed=True):\n",
    "    info = np.finfo(img_array.dtype)\n",
    "    data = img_array.astype(np.float64) / np.max(img_array)\n",
    "    if color_reversed is True:\n",
    "        data = 255 - 255 * data\n",
    "    elif color_reversed is False:\n",
    "        data = 255 * data\n",
    "    # data = (data + 1024) * 0.125\n",
    "    img = data.astype(np.uint8)\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    # cv2.imshow('test', img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def dfs_showdir(path, depth):\n",
    "    if depth == 0:\n",
    "        print(\"root:[\" + path + \"]\")\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if '.git' not in item:\n",
    "            print(\"|      \" * depth + \"+--\" + item)\n",
    "\n",
    "            newitem = path +'/'+ item\n",
    "            if os.path.isdir(newitem):\n",
    "                dfs_showdir(newitem, depth +1)\n",
    "    # print(path_list)\n",
    "\n",
    "\n",
    "def isdir(x):\n",
    "    return os.path.isdir(x) and x != '.svn'\n",
    "\n",
    "\n",
    "def mkfloders(src,tar):\n",
    "    paths = os.listdir(src)\n",
    "    paths = map(lambda name:os.path.join(src, name), paths)\n",
    "    paths = list(filter(isdir, paths))\n",
    "    if(len(paths)<=0):\n",
    "        return\n",
    "    for i in paths:\n",
    "        (filepath, filename)=os.path.split(i)\n",
    "        targetpath = os.path.join(tar,filename)\n",
    "        not os.path.isdir(targetpath) and os.mkdir(targetpath)\n",
    "        mkfloders(i,targetpath)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "\n",
    "    isExists = os.path.exists(path)\n",
    "\n",
    "    if not isExists:\n",
    "        os.makedirs(path)\n",
    "        print(path + ' successfully be made!')\n",
    "        return True\n",
    "    else:\n",
    "        print(path + ' the folder already existed!')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189add5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydicom' has no attribute 'read_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m     UID \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdicom_num\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UID\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mgetUID_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdict\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36mgetUID_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetUID_file\u001b[39m(path):\n\u001b[1;32m---> 35\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[43mloadFileInformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     UID \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdicom_num\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UID\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mloadFileInformation\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloadFileInformation\u001b[39m(filename):\n\u001b[0;32m     30\u001b[0m     information \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 31\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mdicomio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m(filename, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m     information[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdicom_num\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mSOPInstanceUID\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# information['PatientID'] = ds.PatientID\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# information['PatientName'] = ds.PatientName\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# information['PatientBirthDate'] = ds.PatientBirthDate\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# information['Manufacturer'] = ds.Manufacturer\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# information['NumberOfFrames'] = ds.NumberOfFrames\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydicom' has no attribute 'read_file'"
     ]
    }
   ],
   "source": [
    "# getUID.py\n",
    "\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "# path = 'Data/02-06-2020/DICOM/Lung_Dx-G0011'\n",
    "# path = '/home/wangshuo/Desktop/test_data/Lung-PET-CT-Dx/G0011'\n",
    "# path = 'Data/02-06-2020/DICOM/Lung_Dx-G0011/04-29-2009-LUNGC-51228/2.000000-A phase 5mm Stnd SS50-53792/2-017.dcm'\n",
    "path = 'Lung-PET-CT-Dx/Lung_Dx-E0001/10-25-2007-NA-lung-83596/3.000000-5mm Lung SS50-36046/'\n",
    "\n",
    "\n",
    "def getUID_path(path):\n",
    "    dict = {}\n",
    "    list = os.listdir(path)\n",
    "\n",
    "    for date in list:\n",
    "        date_path = os.path.join(path, date)\n",
    "        series_list = os.listdir(date_path)\n",
    "        series_list.sort()\n",
    "\n",
    "        for series in series_list:\n",
    "            series_path = os.path.join(date_path, series)\n",
    "            dicom_list = os.listdir(series_path)\n",
    "            dicom_list.sort()\n",
    "\n",
    "            for dicom in dicom_list:\n",
    "                dicom_path = os.path.join(series_path, dicom)\n",
    "                info = loadFileInformation(dicom_path)\n",
    "                dict[info['dicom_num']] = (dicom_path, dicom)\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "def getUID_file(path):\n",
    "    info = loadFileInformation(path)\n",
    "    UID = info['dicom_num']\n",
    "    return UID\n",
    "\n",
    "dict = getUID_file(path)\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data_from_XML.py\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "\n",
    "def get_category(category_file):\n",
    "    class_list = []\n",
    "    with open(category_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            class_list.append(line.rstrip('\\n'))\n",
    "\n",
    "    return class_list\n",
    "\n",
    "\n",
    "class XML_preprocessor(object):\n",
    "\n",
    "    def __init__(self, data_path, num_classes, normalize=False):\n",
    "        self.path_prefix = data_path\n",
    "        self.num_classes = num_classes\n",
    "        self.normalization = normalize\n",
    "        self.data = dict()\n",
    "        self._preprocess_XML()\n",
    "\n",
    "    def _preprocess_XML(self):\n",
    "        filenames = os.listdir(self.path_prefix)\n",
    "        for filename in filenames:\n",
    "            tree = ElementTree.parse(os.path.join(self.path_prefix, filename))\n",
    "            root = tree.getroot()\n",
    "            bounding_boxes = []\n",
    "            one_hot_classes = []\n",
    "            size_tree = root.find('size')\n",
    "            width = float(size_tree.find('width').text)\n",
    "            height = float(size_tree.find('height').text)\n",
    "            for object_tree in root.findall('object'):\n",
    "                for bounding_box in object_tree.iter('bndbox'):\n",
    "                    if self.normalization:\n",
    "                        xmin = float(bounding_box.find('xmin').text)/width\n",
    "                        ymin = float(bounding_box.find('ymin').text)/height\n",
    "                        xmax = float(bounding_box.find('xmax').text)/width\n",
    "                        ymax = float(bounding_box.find('ymax').text)/height\n",
    "                    else:\n",
    "                        xmin = float(bounding_box.find('xmin').text)\n",
    "                        ymin = float(bounding_box.find('ymin').text)\n",
    "                        xmax = float(bounding_box.find('xmax').text)\n",
    "                        ymax = float(bounding_box.find('ymax').text)\n",
    "                bounding_box = [xmin,ymin,xmax,ymax]\n",
    "                bounding_boxes.append(bounding_box)\n",
    "                class_name = object_tree.find('name').text\n",
    "                one_hot_class = self._to_one_hot(class_name)\n",
    "                one_hot_classes.append(one_hot_class)\n",
    "            # image_name = root.find('filename').text\n",
    "            image_name = filename\n",
    "            bounding_boxes = np.asarray(bounding_boxes)\n",
    "            one_hot_classes = np.asarray(one_hot_classes)\n",
    "            image_data = np.hstack((bounding_boxes, one_hot_classes))\n",
    "            self.data[image_name] = image_data\n",
    "\n",
    "    def _to_one_hot(self, name):\n",
    "        one_hot_vector = [0] * self.num_classes\n",
    "        if name == 'A':\n",
    "            one_hot_vector[0] = 1\n",
    "        elif name == 'B':\n",
    "            one_hot_vector[1] = 1\n",
    "        elif name == 'E':\n",
    "            one_hot_vector[2] = 1\n",
    "        elif name == 'G':\n",
    "            one_hot_vector[3] = 1\n",
    "        else:\n",
    "            print('unknown label: %s' %name)\n",
    "\n",
    "        return one_hot_vector\n",
    "\n",
    "\n",
    "## example on how to use it\n",
    "# import pickle\n",
    "# data = XML_preprocessor('VOC2007/Annotations/').data\n",
    "# pickle.dump(data,open('VOC2007.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
